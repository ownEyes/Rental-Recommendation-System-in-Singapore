{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add required cols for frontend display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "processed_data = pd.read_csv('./dataSource/processed_data_merged.csv')\n",
    "merged_data=pd.read_csv('./dataSource/data_merged(final+version).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_nan = merged_data.columns[merged_data.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>host_about</th>\n",
       "      <th>bathrooms_text</th>\n",
       "      <th>beds</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For 3 rooms.Book room 1&amp;2 and room 4&lt;br /&gt;&lt;br ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi My name is Belinda -Housekeeper \\n\\nI would...</td>\n",
       "      <td>1 private bath</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.78</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;b&gt;The space&lt;/b&gt;&lt;br /&gt;Vocational Stay Deluxe B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi My name is Belinda -Housekeeper \\n\\nI would...</td>\n",
       "      <td>Shared half-bath</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Like your own home, 24hrs access.&lt;br /&gt;&lt;br /&gt;&lt;...</td>\n",
       "      <td>Quiet and view of the playground with exercise...</td>\n",
       "      <td>Hi My name is Belinda -Housekeeper \\n\\nI would...</td>\n",
       "      <td>Shared half-bath</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.41</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>**IMPORTANT NOTES:  READ BEFORE YOU BOOK! &lt;br ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K2 Guesthouse is designed for guests who want ...</td>\n",
       "      <td>2 shared baths</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.53</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lovely home for the special guest !&lt;br /&gt;&lt;br /...</td>\n",
       "      <td>Bus stop &lt;br /&gt;Food center &lt;br /&gt;Supermarket</td>\n",
       "      <td>K2 Guesthouse is designed for guests who want ...</td>\n",
       "      <td>2.5 shared baths</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>Peaceful city view, night scape and green outl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Constant traveler. For work and pleasure.</td>\n",
       "      <td>1 bath</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>Geylang still reigns as a popular buzzing food...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alger</td>\n",
       "      <td>2 baths</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3440</th>\n",
       "      <td>Experience luxury in this 3-bedroom condo at R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 bath</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>Keep it simple at this peaceful and centrally-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi Guest,\\n\\nI am outgoing, loves to travel an...</td>\n",
       "      <td>1.5 baths</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>Show up and start living from day one in Singa...</td>\n",
       "      <td>The high-end Orchard neighborhood is the place...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 bath</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3443 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  \\\n",
       "0     For 3 rooms.Book room 1&2 and room 4<br /><br ...   \n",
       "1     <b>The space</b><br />Vocational Stay Deluxe B...   \n",
       "2     Like your own home, 24hrs access.<br /><br /><...   \n",
       "3     **IMPORTANT NOTES:  READ BEFORE YOU BOOK! <br ...   \n",
       "4     Lovely home for the special guest !<br /><br /...   \n",
       "...                                                 ...   \n",
       "3438  Peaceful city view, night scape and green outl...   \n",
       "3439  Geylang still reigns as a popular buzzing food...   \n",
       "3440  Experience luxury in this 3-bedroom condo at R...   \n",
       "3441  Keep it simple at this peaceful and centrally-...   \n",
       "3442  Show up and start living from day one in Singa...   \n",
       "\n",
       "                                  neighborhood_overview  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2     Quiet and view of the playground with exercise...   \n",
       "3                                                   NaN   \n",
       "4          Bus stop <br />Food center <br />Supermarket   \n",
       "...                                                 ...   \n",
       "3438                                                NaN   \n",
       "3439                                                NaN   \n",
       "3440                                                NaN   \n",
       "3441                                                NaN   \n",
       "3442  The high-end Orchard neighborhood is the place...   \n",
       "\n",
       "                                             host_about    bathrooms_text  \\\n",
       "0     Hi My name is Belinda -Housekeeper \\n\\nI would...    1 private bath   \n",
       "1     Hi My name is Belinda -Housekeeper \\n\\nI would...  Shared half-bath   \n",
       "2     Hi My name is Belinda -Housekeeper \\n\\nI would...  Shared half-bath   \n",
       "3     K2 Guesthouse is designed for guests who want ...    2 shared baths   \n",
       "4     K2 Guesthouse is designed for guests who want ...  2.5 shared baths   \n",
       "...                                                 ...               ...   \n",
       "3438         Constant traveler. For work and pleasure.             1 bath   \n",
       "3439                                              Alger           2 baths   \n",
       "3440                                                NaN            1 bath   \n",
       "3441  Hi Guest,\\n\\nI am outgoing, loves to travel an...         1.5 baths   \n",
       "3442                                                NaN            1 bath   \n",
       "\n",
       "      beds  review_scores_rating  review_scores_accuracy  \\\n",
       "0      3.0                  4.44                    4.37   \n",
       "1      1.0                  4.16                    4.22   \n",
       "2      2.0                  4.41                    4.39   \n",
       "3      1.0                  4.40                    4.16   \n",
       "4      1.0                  4.54                    4.64   \n",
       "...    ...                   ...                     ...   \n",
       "3438   1.0                   NaN                     NaN   \n",
       "3439   3.0                   NaN                     NaN   \n",
       "3440   1.0                   NaN                     NaN   \n",
       "3441   1.0                   NaN                     NaN   \n",
       "3442   1.0                   NaN                     NaN   \n",
       "\n",
       "      review_scores_cleanliness  review_scores_checkin  \\\n",
       "0                          4.00                   4.63   \n",
       "1                          4.09                   4.43   \n",
       "2                          4.52                   4.63   \n",
       "3                          4.26                   4.47   \n",
       "4                          4.21                   4.64   \n",
       "...                         ...                    ...   \n",
       "3438                        NaN                    NaN   \n",
       "3439                        NaN                    NaN   \n",
       "3440                        NaN                    NaN   \n",
       "3441                        NaN                    NaN   \n",
       "3442                        NaN                    NaN   \n",
       "\n",
       "      review_scores_communication  review_scores_location  review_scores_value  \n",
       "0                            4.78                    4.26                 4.32  \n",
       "1                            4.43                    4.17                 4.04  \n",
       "2                            4.64                    4.50                 4.36  \n",
       "3                            4.42                    4.53                 4.63  \n",
       "4                            4.57                    4.64                 4.43  \n",
       "...                           ...                     ...                  ...  \n",
       "3438                          NaN                     NaN                  NaN  \n",
       "3439                          NaN                     NaN                  NaN  \n",
       "3440                          NaN                     NaN                  NaN  \n",
       "3441                          NaN                     NaN                  NaN  \n",
       "3442                          NaN                     NaN                  NaN  \n",
       "\n",
       "[3443 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data[columns_with_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_count(df):\n",
    "    print(\"Shape before delete:\", df.shape)\n",
    "    df_cleaned = df.dropna()\n",
    "    print(\"Shape after delete:\", df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before delete: (3443, 30)\n",
      "Shape after delete: (3443, 30)\n"
     ]
    }
   ],
   "source": [
    "nan_count(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before delete: (3443, 36)\n",
      "Shape after delete: (1006, 36)\n"
     ]
    }
   ],
   "source": [
    "nan_count(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>picture_url</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>host_about</th>\n",
       "      <th>host_verifications</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>distance_to_mrt</th>\n",
       "      <th>closest_mrt_name</th>\n",
       "      <th>closest_mrt_stop_id</th>\n",
       "      <th>closest_mall_distance</th>\n",
       "      <th>closest_mall_name</th>\n",
       "      <th>closest_mall_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71609</td>\n",
       "      <td>https://www.airbnb.com/rooms/71609</td>\n",
       "      <td>Villa in Singapore · ★4.44 · 2 bedrooms · 3 be...</td>\n",
       "      <td>For 3 rooms.Book room 1&amp;2 and room 4&lt;br /&gt;&lt;br ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/24453191/3580...</td>\n",
       "      <td>367042</td>\n",
       "      <td>Belinda</td>\n",
       "      <td>Hi My name is Belinda -Housekeeper \\n\\nI would...</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.78</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.32</td>\n",
       "      <td>0.496792</td>\n",
       "      <td>UPPER CHANGI MRT STATION</td>\n",
       "      <td>DT34</td>\n",
       "      <td>0.712034</td>\n",
       "      <td>Eastpoint Mall</td>\n",
       "      <td>3 Simei Street 6, Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71896</td>\n",
       "      <td>https://www.airbnb.com/rooms/71896</td>\n",
       "      <td>Home in Singapore · ★4.16 · 1 bedroom · 1 bed ...</td>\n",
       "      <td>&lt;b&gt;The space&lt;/b&gt;&lt;br /&gt;Vocational Stay Deluxe B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/2440674/ac4f4...</td>\n",
       "      <td>367042</td>\n",
       "      <td>Belinda</td>\n",
       "      <td>Hi My name is Belinda -Housekeeper \\n\\nI would...</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0.678619</td>\n",
       "      <td>UPPER CHANGI MRT STATION</td>\n",
       "      <td>DT34</td>\n",
       "      <td>0.771430</td>\n",
       "      <td>Tampines Mart</td>\n",
       "      <td>Tampines Street 32, Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71903</td>\n",
       "      <td>https://www.airbnb.com/rooms/71903</td>\n",
       "      <td>Home in Singapore · ★4.41 · 1 bedroom · 2 beds...</td>\n",
       "      <td>Like your own home, 24hrs access.&lt;br /&gt;&lt;br /&gt;&lt;...</td>\n",
       "      <td>Quiet and view of the playground with exercise...</td>\n",
       "      <td>https://a0.muscache.com/pictures/568743/7bc623...</td>\n",
       "      <td>367042</td>\n",
       "      <td>Belinda</td>\n",
       "      <td>Hi My name is Belinda -Housekeeper \\n\\nI would...</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.36</td>\n",
       "      <td>0.400694</td>\n",
       "      <td>UPPER CHANGI MRT STATION</td>\n",
       "      <td>DT34</td>\n",
       "      <td>0.930587</td>\n",
       "      <td>Eastpoint Mall</td>\n",
       "      <td>3 Simei Street 6, Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275343</td>\n",
       "      <td>https://www.airbnb.com/rooms/275343</td>\n",
       "      <td>Rental unit in Singapore · ★4.40 · 1 bedroom ·...</td>\n",
       "      <td>**IMPORTANT NOTES:  READ BEFORE YOU BOOK! &lt;br ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/miso/Hosting-...</td>\n",
       "      <td>1439258</td>\n",
       "      <td>Kay</td>\n",
       "      <td>K2 Guesthouse is designed for guests who want ...</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.53</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.580759</td>\n",
       "      <td>QUEENSTOWN MRT STATION</td>\n",
       "      <td>EW19</td>\n",
       "      <td>0.373537</td>\n",
       "      <td>Anchorpoint Shopping Centre</td>\n",
       "      <td>370 Alexandra Rd, Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275344</td>\n",
       "      <td>https://www.airbnb.com/rooms/275344</td>\n",
       "      <td>Rental unit in Singapore · ★4.54 · 1 bedroom ·...</td>\n",
       "      <td>Lovely home for the special guest !&lt;br /&gt;&lt;br /...</td>\n",
       "      <td>Bus stop &lt;br /&gt;Food center &lt;br /&gt;Supermarket</td>\n",
       "      <td>https://a0.muscache.com/pictures/miso/Hosting-...</td>\n",
       "      <td>1439258</td>\n",
       "      <td>Kay</td>\n",
       "      <td>K2 Guesthouse is designed for guests who want ...</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.612490</td>\n",
       "      <td>REDHILL MRT STATION</td>\n",
       "      <td>EW18</td>\n",
       "      <td>0.482796</td>\n",
       "      <td>Dawson Place</td>\n",
       "      <td>57 Dawson Rd, Singapore 142057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>920638892602895042</td>\n",
       "      <td>https://www.airbnb.com/rooms/920638892602895042</td>\n",
       "      <td>Rental unit in Singapore · ★New · 1 bedroom · ...</td>\n",
       "      <td>Peaceful city view, night scape and green outl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/miso/Hosting-...</td>\n",
       "      <td>24060343</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Constant traveler. For work and pleasure.</td>\n",
       "      <td>['email', 'phone', 'work_email']</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836969</td>\n",
       "      <td>ORCHARD MRT STATION</td>\n",
       "      <td>NS22</td>\n",
       "      <td>0.426396</td>\n",
       "      <td>Great World City</td>\n",
       "      <td>1 Kim Seng Promenade, Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>921632579190690942</td>\n",
       "      <td>https://www.airbnb.com/rooms/921632579190690942</td>\n",
       "      <td>Rental unit in Singapore · ★New · 3 bedrooms ·...</td>\n",
       "      <td>Geylang still reigns as a popular buzzing food...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/miso/Hosting-...</td>\n",
       "      <td>323944827</td>\n",
       "      <td>Alger</td>\n",
       "      <td>Alger</td>\n",
       "      <td>['phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623004</td>\n",
       "      <td>MOUNTBATTEN MRT STATION</td>\n",
       "      <td>CC7</td>\n",
       "      <td>0.329886</td>\n",
       "      <td>Guillemard Village</td>\n",
       "      <td>102 Guillemard Rd, Singapore 399719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3440</th>\n",
       "      <td>921860100684819207</td>\n",
       "      <td>https://www.airbnb.com/rooms/921860100684819207</td>\n",
       "      <td>Rental unit in Singapore · ★New · 1 bedroom · ...</td>\n",
       "      <td>Experience luxury in this 3-bedroom condo at R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/miso/Hosting-...</td>\n",
       "      <td>9234861</td>\n",
       "      <td>Luc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788851</td>\n",
       "      <td>FORT CANNING MRT STATION</td>\n",
       "      <td>DT20</td>\n",
       "      <td>0.469126</td>\n",
       "      <td>Concorde Shopping Centre</td>\n",
       "      <td>317 Outram Rd, Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>922639973995552700</td>\n",
       "      <td>https://www.airbnb.com/rooms/922639973995552700</td>\n",
       "      <td>Rental unit in Singapore · ★New · 1 bedroom · ...</td>\n",
       "      <td>Keep it simple at this peaceful and centrally-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/34975b5f-4d66...</td>\n",
       "      <td>35666883</td>\n",
       "      <td>Ed</td>\n",
       "      <td>Hi Guest,\\n\\nI am outgoing, loves to travel an...</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.441732</td>\n",
       "      <td>DAKOTA MRT STATION</td>\n",
       "      <td>CC8</td>\n",
       "      <td>0.108850</td>\n",
       "      <td>Katong Shopping Centre</td>\n",
       "      <td>865 Mountbatten Rd, Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>923090996470704816</td>\n",
       "      <td>https://www.airbnb.com/rooms/923090996470704816</td>\n",
       "      <td>Rental unit in Singapore · ★New · 1 bedroom · ...</td>\n",
       "      <td>Show up and start living from day one in Singa...</td>\n",
       "      <td>The high-end Orchard neighborhood is the place...</td>\n",
       "      <td>https://a0.muscache.com/pictures/prohost-api/H...</td>\n",
       "      <td>466330896</td>\n",
       "      <td>Blueground</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.866490</td>\n",
       "      <td>ORCHARD MRT STATION</td>\n",
       "      <td>NS22</td>\n",
       "      <td>0.592316</td>\n",
       "      <td>Tanglin Place</td>\n",
       "      <td>91 Tanglin Rd, Singapore 247918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3443 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                      listing_url  \\\n",
       "0                  71609               https://www.airbnb.com/rooms/71609   \n",
       "1                  71896               https://www.airbnb.com/rooms/71896   \n",
       "2                  71903               https://www.airbnb.com/rooms/71903   \n",
       "3                 275343              https://www.airbnb.com/rooms/275343   \n",
       "4                 275344              https://www.airbnb.com/rooms/275344   \n",
       "...                  ...                                              ...   \n",
       "3438  920638892602895042  https://www.airbnb.com/rooms/920638892602895042   \n",
       "3439  921632579190690942  https://www.airbnb.com/rooms/921632579190690942   \n",
       "3440  921860100684819207  https://www.airbnb.com/rooms/921860100684819207   \n",
       "3441  922639973995552700  https://www.airbnb.com/rooms/922639973995552700   \n",
       "3442  923090996470704816  https://www.airbnb.com/rooms/923090996470704816   \n",
       "\n",
       "                                                   name  \\\n",
       "0     Villa in Singapore · ★4.44 · 2 bedrooms · 3 be...   \n",
       "1     Home in Singapore · ★4.16 · 1 bedroom · 1 bed ...   \n",
       "2     Home in Singapore · ★4.41 · 1 bedroom · 2 beds...   \n",
       "3     Rental unit in Singapore · ★4.40 · 1 bedroom ·...   \n",
       "4     Rental unit in Singapore · ★4.54 · 1 bedroom ·...   \n",
       "...                                                 ...   \n",
       "3438  Rental unit in Singapore · ★New · 1 bedroom · ...   \n",
       "3439  Rental unit in Singapore · ★New · 3 bedrooms ·...   \n",
       "3440  Rental unit in Singapore · ★New · 1 bedroom · ...   \n",
       "3441  Rental unit in Singapore · ★New · 1 bedroom · ...   \n",
       "3442  Rental unit in Singapore · ★New · 1 bedroom · ...   \n",
       "\n",
       "                                            description  \\\n",
       "0     For 3 rooms.Book room 1&2 and room 4<br /><br ...   \n",
       "1     <b>The space</b><br />Vocational Stay Deluxe B...   \n",
       "2     Like your own home, 24hrs access.<br /><br /><...   \n",
       "3     **IMPORTANT NOTES:  READ BEFORE YOU BOOK! <br ...   \n",
       "4     Lovely home for the special guest !<br /><br /...   \n",
       "...                                                 ...   \n",
       "3438  Peaceful city view, night scape and green outl...   \n",
       "3439  Geylang still reigns as a popular buzzing food...   \n",
       "3440  Experience luxury in this 3-bedroom condo at R...   \n",
       "3441  Keep it simple at this peaceful and centrally-...   \n",
       "3442  Show up and start living from day one in Singa...   \n",
       "\n",
       "                                  neighborhood_overview  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2     Quiet and view of the playground with exercise...   \n",
       "3                                                   NaN   \n",
       "4          Bus stop <br />Food center <br />Supermarket   \n",
       "...                                                 ...   \n",
       "3438                                                NaN   \n",
       "3439                                                NaN   \n",
       "3440                                                NaN   \n",
       "3441                                                NaN   \n",
       "3442  The high-end Orchard neighborhood is the place...   \n",
       "\n",
       "                                            picture_url    host_id  \\\n",
       "0     https://a0.muscache.com/pictures/24453191/3580...     367042   \n",
       "1     https://a0.muscache.com/pictures/2440674/ac4f4...     367042   \n",
       "2     https://a0.muscache.com/pictures/568743/7bc623...     367042   \n",
       "3     https://a0.muscache.com/pictures/miso/Hosting-...    1439258   \n",
       "4     https://a0.muscache.com/pictures/miso/Hosting-...    1439258   \n",
       "...                                                 ...        ...   \n",
       "3438  https://a0.muscache.com/pictures/miso/Hosting-...   24060343   \n",
       "3439  https://a0.muscache.com/pictures/miso/Hosting-...  323944827   \n",
       "3440  https://a0.muscache.com/pictures/miso/Hosting-...    9234861   \n",
       "3441  https://a0.muscache.com/pictures/34975b5f-4d66...   35666883   \n",
       "3442  https://a0.muscache.com/pictures/prohost-api/H...  466330896   \n",
       "\n",
       "       host_name                                         host_about  \\\n",
       "0        Belinda  Hi My name is Belinda -Housekeeper \\n\\nI would...   \n",
       "1        Belinda  Hi My name is Belinda -Housekeeper \\n\\nI would...   \n",
       "2        Belinda  Hi My name is Belinda -Housekeeper \\n\\nI would...   \n",
       "3            Kay  K2 Guesthouse is designed for guests who want ...   \n",
       "4            Kay  K2 Guesthouse is designed for guests who want ...   \n",
       "...          ...                                                ...   \n",
       "3438       Chris         Constant traveler. For work and pleasure.    \n",
       "3439       Alger                                              Alger   \n",
       "3440         Luc                                                NaN   \n",
       "3441          Ed  Hi Guest,\\n\\nI am outgoing, loves to travel an...   \n",
       "3442  Blueground                                                NaN   \n",
       "\n",
       "                    host_verifications  ... review_scores_checkin  \\\n",
       "0                   ['email', 'phone']  ...                  4.63   \n",
       "1                   ['email', 'phone']  ...                  4.43   \n",
       "2                   ['email', 'phone']  ...                  4.63   \n",
       "3                   ['email', 'phone']  ...                  4.47   \n",
       "4                   ['email', 'phone']  ...                  4.64   \n",
       "...                                ...  ...                   ...   \n",
       "3438  ['email', 'phone', 'work_email']  ...                   NaN   \n",
       "3439                         ['phone']  ...                   NaN   \n",
       "3440                ['email', 'phone']  ...                   NaN   \n",
       "3441                ['email', 'phone']  ...                   NaN   \n",
       "3442                ['email', 'phone']  ...                   NaN   \n",
       "\n",
       "     review_scores_communication  review_scores_location  review_scores_value  \\\n",
       "0                           4.78                    4.26                 4.32   \n",
       "1                           4.43                    4.17                 4.04   \n",
       "2                           4.64                    4.50                 4.36   \n",
       "3                           4.42                    4.53                 4.63   \n",
       "4                           4.57                    4.64                 4.43   \n",
       "...                          ...                     ...                  ...   \n",
       "3438                         NaN                     NaN                  NaN   \n",
       "3439                         NaN                     NaN                  NaN   \n",
       "3440                         NaN                     NaN                  NaN   \n",
       "3441                         NaN                     NaN                  NaN   \n",
       "3442                         NaN                     NaN                  NaN   \n",
       "\n",
       "     distance_to_mrt          closest_mrt_name  closest_mrt_stop_id  \\\n",
       "0           0.496792  UPPER CHANGI MRT STATION                 DT34   \n",
       "1           0.678619  UPPER CHANGI MRT STATION                 DT34   \n",
       "2           0.400694  UPPER CHANGI MRT STATION                 DT34   \n",
       "3           0.580759    QUEENSTOWN MRT STATION                 EW19   \n",
       "4           0.612490       REDHILL MRT STATION                 EW18   \n",
       "...              ...                       ...                  ...   \n",
       "3438        0.836969       ORCHARD MRT STATION                 NS22   \n",
       "3439        0.623004   MOUNTBATTEN MRT STATION                  CC7   \n",
       "3440        0.788851  FORT CANNING MRT STATION                 DT20   \n",
       "3441        1.441732        DAKOTA MRT STATION                  CC8   \n",
       "3442        0.866490       ORCHARD MRT STATION                 NS22   \n",
       "\n",
       "     closest_mall_distance            closest_mall_name  \\\n",
       "0                 0.712034               Eastpoint Mall   \n",
       "1                 0.771430                Tampines Mart   \n",
       "2                 0.930587               Eastpoint Mall   \n",
       "3                 0.373537  Anchorpoint Shopping Centre   \n",
       "4                 0.482796                 Dawson Place   \n",
       "...                    ...                          ...   \n",
       "3438              0.426396             Great World City   \n",
       "3439              0.329886           Guillemard Village   \n",
       "3440              0.469126     Concorde Shopping Centre   \n",
       "3441              0.108850       Katong Shopping Centre   \n",
       "3442              0.592316                Tanglin Place   \n",
       "\n",
       "                     closest_mall_address  \n",
       "0             3 Simei Street 6, Singapore  \n",
       "1           Tampines Street 32, Singapore  \n",
       "2             3 Simei Street 6, Singapore  \n",
       "3             370 Alexandra Rd, Singapore  \n",
       "4          57 Dawson Rd, Singapore 142057  \n",
       "...                                   ...  \n",
       "3438      1 Kim Seng Promenade, Singapore  \n",
       "3439  102 Guillemard Rd, Singapore 399719  \n",
       "3440             317 Outram Rd, Singapore  \n",
       "3441        865 Mountbatten Rd, Singapore  \n",
       "3442      91 Tanglin Rd, Singapore 247918  \n",
       "\n",
       "[3443 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>neighbourhood_group_cleansed</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_months</th>\n",
       "      <th>maximum_months</th>\n",
       "      <th>distance_to_mrt</th>\n",
       "      <th>...</th>\n",
       "      <th>Wifi</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>Backyard</th>\n",
       "      <th>TV</th>\n",
       "      <th>refrigerator</th>\n",
       "      <th>Microwave</th>\n",
       "      <th>Oven</th>\n",
       "      <th>Pets</th>\n",
       "      <th>stove</th>\n",
       "      <th>fan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, neighbourhood_cleansed, neighbourhood_group_cleansed, latitude, longitude, room_type, price, minimum_months, maximum_months, distance_to_mrt, closest_mrt_name, closest_mrt_stop_id, closest_mall_distance, closest_mall_name, closest_mall_address, conditioning, BBQ, gym, pool, dryer, Wifi, kitchen, Backyard, TV, refrigerator, Microwave, Oven, Pets, stove, fan]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_names = processed_data[merged_data['name'].isnull() | (merged_data['name'] == '')]\n",
    "\n",
    "# 打印结果\n",
    "empty_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['name']= merged_data['name']+' in '+merged_data['neighbourhood_cleansed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_nan = merged_data.isna().any()\n",
    "\n",
    "# 提取包含缺失值的列\n",
    "data_with_nan = merged_data[cols_with_nan[cols_with_nan].index]\n",
    "data_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_merge = ['name', 'details', 'accommodates', 'picture_url',\n",
    "                   'review_scores_rating', 'review_scores_accuracy',\n",
    "                   'review_scores_cleanliness', 'review_scores_checkin',\n",
    "                   'review_scores_communication', 'review_scores_location',\n",
    "                   'review_scores_value', 'listing_url']\n",
    "merged_data['details'] = merged_data['name'].str.split(' · ',n=2).str[2]\n",
    "merged_data['name'] = merged_data['name'].str.split(' in ').str[0]\n",
    "merged_data['name']= merged_data['name']+' in '+merged_data['neighbourhood_cleansed']\n",
    "\n",
    "processed_data = processed_data.merge(merged_data[['id'] + columns_to_merge],\n",
    "                                       on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_nan = processed_data.isna().any()\n",
    "\n",
    "# 提取包含缺失值的列\n",
    "data_with_nan = processed_data[cols_with_nan[cols_with_nan].index]\n",
    "data_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_details = processed_data[processed_data['details'].isnull() | (processed_data['details'] == '')]\n",
    "\n",
    "# 打印结果\n",
    "empty_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data[~(processed_data['details'].isnull() | (processed_data['details'] == ''))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.to_csv('./dataSource/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "processed_data = pd.read_csv('./dataSource/processed_data_merged.csv')\n",
    "merged_data=pd.read_csv('./dataSource/data_merged(final+version).csv')\n",
    "\n",
    "# def replace_value(row):\n",
    "#     if 'Singapore' in row['name']:\n",
    "#         return row['name'].replace('Singapore', row['neighbourhood_cleansed'])\n",
    "#     else:\n",
    "#         return row['name']\n",
    "    \n",
    "\n",
    "# merged_data['name'] = merged_data['name'].str.split('Singapore').str[0]\n",
    "column1_to_add = merged_data['name'].str.split(' · ',n=2).str[2]\n",
    "\n",
    "merged_data['name'] = merged_data['name'].str.split(' in ').str[0]\n",
    "merged_data['name']= merged_data['name']+' in '+merged_data['neighbourhood_cleansed']\n",
    "\n",
    "column2_to_add=merged_data['name']\n",
    "column3_to_add=merged_data['accommodates']\n",
    "column4_to_add=merged_data['picture_url']\n",
    "\n",
    "processed_data.insert(1, 'details', column1_to_add)\n",
    "processed_data.insert(1, 'name', column2_to_add)\n",
    "processed_data.insert(16, 'accommodates', column3_to_add)\n",
    "processed_data.insert(5, 'picture_url', column4_to_add)\n",
    "\n",
    "processed_data.to_csv('processed_data_merged_final_v1.csv', index=False)\n",
    "\n",
    "new=pd.read_csv('./csv_output/processed_data_merged_final_v1.csv')\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete row with empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 bedrooms · 3 beds · 1 private bath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 bedroom · 1 bed · Shared half-bath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 bedroom · 2 beds · Shared half-bath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 bedroom · 1 bed · 2 shared baths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 bedroom · 1 bed · 2.5 shared baths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>1 bedroom · 1 bed · 1 bath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>3 bedrooms · 3 beds · 2 baths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3440</th>\n",
       "      <td>1 bedroom · 1 bed · 1 bath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>1 bedroom · 1 bed · 1.5 baths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>1 bedroom · 1 bed · 1 bath</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3443 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    details\n",
       "0      2 bedrooms · 3 beds · 1 private bath\n",
       "1      1 bedroom · 1 bed · Shared half-bath\n",
       "2     1 bedroom · 2 beds · Shared half-bath\n",
       "3        1 bedroom · 1 bed · 2 shared baths\n",
       "4      1 bedroom · 1 bed · 2.5 shared baths\n",
       "...                                     ...\n",
       "3438             1 bedroom · 1 bed · 1 bath\n",
       "3439          3 bedrooms · 3 beds · 2 baths\n",
       "3440             1 bedroom · 1 bed · 1 bath\n",
       "3441          1 bedroom · 1 bed · 1.5 baths\n",
       "3442             1 bedroom · 1 bed · 1 bath\n",
       "\n",
       "[3443 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('./csv_output/processed_data_merged_final_v1.csv')\n",
    "columns_with_nan = df.columns[df.isna().any()].tolist()\n",
    "df[columns_with_nan]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape before delete:\", df.shape)\n",
    "df_cleaned = df.dropna()\n",
    "print(\"Shape after delete:\", df_cleaned.shape)\n",
    "df_cleaned.to_csv('./csv_output/processed_data_merged_final_v2.csv', index=False)\n",
    "\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     details\n",
       "1827     NaN\n",
       "2082     NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deleted = df[~df.index.isin(df_cleaned.index)]\n",
    "\n",
    "\n",
    "df_deleted_nan_only = df_deleted.loc[:, df_deleted.isna().any()]\n",
    "df_deleted_nan_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add rating cols for default rating-based recommdation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('./csv_output/processed_data_merged_final_v2.csv')\n",
    "df2=pd.read_csv('./dataSource/data_merged(final+version).csv',\n",
    "                usecols=['review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value'])\n",
    "df=pd.concat([df1, df2], axis=1)\n",
    "\n",
    "df.to_csv('./csv_output/processed_data_merged_final_v3.csv', index=False)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add room details for Linze 5002 regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "original = pd.read_csv('./csv_output/processed_data_merged_final_v2.csv')\n",
    "\n",
    "type_to_add=original['name']\n",
    "type_to_add = type_to_add.str.split(' in ').str[0]\n",
    "\n",
    "studio_to_add=original['details']\n",
    "studio_to_add = studio_to_add.apply(lambda x: 1 if 'Studio' in x else 0)\n",
    "\n",
    "shared_bath_to_add=original['details']\n",
    "shared_bath_to_add=shared_bath_to_add.apply(lambda x: 0.5 if 'Shared half-bath' in x else 0)\n",
    "\n",
    "private_bath_to_add=original['details']\n",
    "private_bath_to_add=private_bath_to_add.apply(lambda x: 0.5 if 'Private half-bath' in x else 0)\n",
    "\n",
    "def parse_room_info(info):\n",
    "    counts = {}  \n",
    "\n",
    "\n",
    "    matches = re.findall(r'(\\d+(\\.\\d+)?)\\s*([\\w\\s]+)\\b', info)\n",
    "    for count, _, room_type in matches:\n",
    "        counts[room_type.strip()] = float(count)\n",
    "\n",
    "    return counts\n",
    "\n",
    "parsed_room_info = original['details'].apply(parse_room_info)\n",
    "\n",
    "parsed_df = pd.DataFrame(parsed_room_info.tolist(), index=original.index)\n",
    "\n",
    "\n",
    "df = pd.concat([original, parsed_df], axis=1)\n",
    "df.insert(1, 'types', type_to_add)\n",
    "\n",
    "df[['bedrooms', 'bedroom', 'beds', 'bed', 'shared baths','private bath', 'shared bath', 'baths', 'bath']] = df[['bedrooms', 'bedroom', 'beds', 'bed', 'shared baths','private bath', 'shared bath', 'baths', 'bath']].fillna(0)\n",
    "df['total_bedrooms'] = df['bedrooms'] + df['bedroom']\n",
    "df['total_beds'] = df['beds'] + df['bed']\n",
    "df['total_shared_baths'] = df['shared baths'] + df['shared bath']+shared_bath_to_add\n",
    "\n",
    "df['private bath']=df['private bath']+ private_bath_to_add\n",
    "df['total_baths'] = df['baths'] + df['bath']\n",
    "\n",
    "def get_bath_type(row):\n",
    "    if row['private bath'] != 0:\n",
    "        return 'private'\n",
    "    elif row['total_shared_baths'] != 0:\n",
    "        return 'shared'\n",
    "    elif row['total_baths'] != 0:\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        return 'none'\n",
    "\n",
    "df['bath_type'] = df.apply(get_bath_type, axis=1)\n",
    "\n",
    "df['total_baths'] =df['total_baths'] +df['total_shared_baths']+ df['private bath']\n",
    "\n",
    "\n",
    "df = df.drop(columns=['bedrooms', 'bedroom', 'beds', 'bed', 'shared baths', 'shared bath', 'baths', 'bath','total_shared_baths','private bath'])\n",
    "df.insert(loc=len(df.columns), column='studio', value=studio_to_add)\n",
    "\n",
    "df.to_csv('./csv_output/data_merged_5002_v2.csv', index=False)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=pd.read_csv('./dataSource/reviews.csv')\n",
    "nan_count(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=pd.read_csv('./csv_output/ratingInfo.csv')\n",
    "nan_count(rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Followings for rating estimation from review comments\n",
    "### Delete cols not in en language, check comments by same users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect_langs\n",
    "\n",
    "raw=pd.read_csv('./dataSource/reviews.csv')\n",
    "\n",
    "duplicate_ids = raw['reviewer_id'].duplicated()\n",
    "\n",
    "\n",
    "duplicate=raw[duplicate_ids]\n",
    "duplicate.head()\n",
    "\n",
    "# raw = raw.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows:\", duplicate.shape[0])  \n",
    "print(\"Number of columns:\", duplicate.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_ids = raw['reviewer_name'].duplicated()\n",
    "\n",
    "\n",
    "duplicate=raw[duplicate_ids]\n",
    "duplicate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows:\", duplicate.shape[0])  \n",
    "print(\"Number of columns:\", duplicate.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and drap cols which is not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw.drop(columns=['date', 'id'])\n",
    "\n",
    "def is_all_english_text(text):\n",
    "    try:\n",
    "        langs = detect_langs(text)\n",
    "        for lang in langs:\n",
    "            if lang.lang != 'en':\n",
    "                return False\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "raw = raw[raw['comments'].apply(is_all_english_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_ids = raw['reviewer_id'].duplicated()\n",
    "\n",
    "\n",
    "duplicate=raw[duplicate_ids]\n",
    "print(\"Number of rows:\", duplicate.shape[0])  \n",
    "print(\"Number of columns:\", duplicate.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### asign new user ID for database construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['userID'] = pd.factorize(raw['reviewer_id'])[0] + 1\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save user and their comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import re\n",
    "\n",
    "raw = raw.drop(columns=['reviewer_id'])\n",
    "raw_reset = raw.reset_index(drop=True)\n",
    "# raw_reset['comments'] = raw_reset['comments'].str.replace('<br/>', '\\n')\n",
    "# raw_reset['comments'] = raw_reset['comments'].str.replace('\\n', ' ')\n",
    "\n",
    "raw_reset['comments'] = raw_reset['comments'].apply(lambda x: re.sub(r'<br/>', '\\n', x))\n",
    "raw_reset['comments'] = raw_reset['comments'].apply(lambda x: re.sub(r'\\n+', '\\n', x))\n",
    "\n",
    "commentsInfo=raw_reset[['listing_id','userID','comments']]\n",
    "\n",
    "commentsInfo.to_csv('./csv_output/commentsInfo.csv', index=False)\n",
    "\n",
    "commentsInfo.head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keep unquie user id, generate unquie username, pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userInfo=raw_reset[['userID','reviewer_name']]\n",
    "userInfo = userInfo.rename(columns={'reviewer_name': 'userName'})\n",
    "userInfo = userInfo.drop_duplicates(subset=['userID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### need delete special characters in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_username(username):\n",
    "    pattern = re.compile(r'[^a-zA-Z0-9_]+')\n",
    "    return re.sub(pattern, '_', username)\n",
    "\n",
    "\n",
    "userInfo['userName'] = userInfo['userName'].apply(process_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "used_usernames = set()\n",
    "\n",
    "for index, row in userInfo.iterrows():\n",
    "    username = row['userName']\n",
    "    \n",
    "    if username in used_usernames:\n",
    "        while True:\n",
    "            new_username = f\"{username}_{random.randint(1, 999)}\"\n",
    "            if new_username not in used_usernames and len(new_username) <= 20:\n",
    "                break\n",
    "        userInfo.at[index, 'userName'] = new_username\n",
    "        used_usernames.add(new_username)\n",
    "    else:\n",
    "        used_usernames.add(username)\n",
    "\n",
    "def generate_password(length):\n",
    "    characters = string.ascii_letters + string.digits + string.punctuation\n",
    "    password = ''.join(random.choice(characters) for _ in range(length))\n",
    "    return password\n",
    "\n",
    "\n",
    "userInfo['password'] = userInfo.apply(lambda row: generate_password(random.randint(6, 20)), axis=1)\n",
    "userInfo.to_csv('./csv_output/userInfo.csv', index=False)\n",
    "\n",
    "userInfo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check unquieness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_ids = userInfo['userName'].duplicated()\n",
    "\n",
    "\n",
    "duplicate=userInfo[duplicate_ids]\n",
    "duplicate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows:\", duplicate.shape[0])  \n",
    "print(\"Number of columns:\", duplicate.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_ids = userInfo['userID'].duplicated()\n",
    "\n",
    "\n",
    "duplicate=userInfo[duplicate_ids]\n",
    "duplicate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rating estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from flair.nn import Classifier\n",
    "from flair.data import Sentence\n",
    "import pandas as pd\n",
    "\n",
    "comments=pd.read_csv('./csv_output/commentsInfo.csv')\n",
    "\n",
    "classifier = Classifier.load('sentiment')\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid_mapping(score):\n",
    "    mapped_score = 5 / (1 + math.exp(-score))\n",
    "    return mapped_score\n",
    "\n",
    "def tanh_mapping(score):\n",
    "    mapped_score = 2.5 * math.tanh(score) + 2.5\n",
    "    return mapped_score\n",
    "\n",
    "# def analyze_sentiment(text):\n",
    "#     sentence = Sentence(text)\n",
    "#     classifier.predict(sentence)\n",
    "\n",
    "\n",
    "#     positivity_score = sentence.labels[0].score\n",
    "#     mapped_positivity_score = tanh_mapping(positivity_score)\n",
    "\n",
    "#     estimated_sentiment=sentence.labels[0].value\n",
    "#     # estimated_rating = sigmoid_mapping(positivity_score) if sentence.labels[0].value == 'POSITIVE' else 5 - sigmoid_mapping(positivity_score)\n",
    "#     estimated_rating = mapped_positivity_score if estimated_sentiment == 'POSITIVE' else 5 - mapped_positivity_score\n",
    "    \n",
    "#     return estimated_rating,estimated_sentiment\n",
    "\n",
    "\n",
    "# def exponential_mapping(score, sentiment_value):\n",
    "#     a=7\n",
    "\n",
    "#     normalized_score = (score - 0.9) / 0.1  \n",
    "\n",
    "#     center = 4.5 if sentiment_value == 'POSITIVE' else 0.5\n",
    "\n",
    "#     mapped_score = math.exp((normalized_score - center) * a)  \n",
    "\n",
    "#     mapped_score = mapped_score * 5.0\n",
    "#     return mapped_score\n",
    "import math\n",
    "\n",
    "def exponential_mapping(score, sentiment_value):\n",
    "    a = 2.0  \n",
    "\n",
    "\n",
    "    normalized_score = max(0, min(1, (score - 0.5) / 0.5))\n",
    "\n",
    "\n",
    "    center = 0.99 if sentiment_value == 'POSITIVE' else 0.01\n",
    "\n",
    "\n",
    "    mapped_score = math.exp(-a * abs(normalized_score - center))\n",
    "\n",
    "    mapped_score = mapped_score * 5.0\n",
    "\n",
    "    return mapped_score\n",
    "\n",
    "\n",
    "def analyze_sentiment_flair(text):\n",
    "    sentence = Sentence(text)\n",
    "    classifier.predict(sentence)\n",
    "\n",
    "    positivity_score = sentence.labels[0].score\n",
    "    sentiment_value = sentence.labels[0].value\n",
    "\n",
    "    estimated_rating = exponential_mapping(positivity_score, sentiment_value)\n",
    "\n",
    "    return estimated_rating, sentiment_value,positivity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments[['estimated_rating_flair','estimated_sentiment_flair','probability']] = comments['comments'].apply(lambda x: pd.Series(analyze_sentiment_flair(x)))\n",
    "comments.head()\n",
    "comments.to_csv('./csv_output/commentsInfo_flair_exp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "comments=pd.read_csv('./csv_output/commentsInfo_flair_exp.csv')\n",
    "\n",
    "def analyze_sentiment_textblob(text):\n",
    "    testimonial = TextBlob(text)\n",
    "    \n",
    "    sentiment_value = testimonial.sentiment.polarity\n",
    "    subjectivity_value = testimonial.sentiment.subjectivity\n",
    "    estimated_rating=(testimonial.sentiment.polarity+1)*2.5\n",
    "    return estimated_rating,sentiment_value,subjectivity_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments[['estimated_rating_textblob','estimated_sentiment_textblob','estimated_subjectivity_textblob']] = comments['comments'].apply(lambda x: pd.Series(analyze_sentiment_textblob(x)))\n",
    "comments.head()\n",
    "comments.to_csv('./csv_output/commentsInfo_flair_textblob.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import asent\n",
    "comments=pd.read_csv('./csv_output/commentsInfo_flair_textblob.csv')\n",
    "# create spacy pipeline\n",
    "nlp = spacy.blank('en')\n",
    "nlp.add_pipe('sentencizer')\n",
    "\n",
    "# add the rule-based sentiment model\n",
    "nlp.add_pipe(\"asent_en_v1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_asent(nlp,text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    neg_value = doc._.polarity.negative\n",
    "    neu_value = doc._.polarity.neutral\n",
    "    pos_value = doc._.polarity.positive\n",
    "    compound_value=doc._.polarity.compound\n",
    "    # estimated_rating=sentiment_mapping(neg_value,neu_value,pos_value,compound_value)\n",
    "    # return neg_value,neu_value,pos_value,compound_value,estimated_rating\n",
    "    return neg_value,neu_value,pos_value,compound_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments[['neg_value_asent','neu_value_asent','pos_value_asent','compound_value_asent','estimated_rating_asent']] = comments['comments'].apply(lambda x: pd.Series(analyze_sentiment_asent(nlp,x)))\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_csv('./csv_output/commentsInfo_flair_textblob_asent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install spacytextblob\n",
    "!python -m textblob.download_corpora\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "# comments=pd.read_csv('./csv_output/commentsInfo_flair_textblob_asent.csv')\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# nlp.add_pipe(\"spacytextblob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analyze_sentiment_spacytextblob(nlp,text):\n",
    "#     doc = nlp(text)\n",
    "    \n",
    "#     sentiment_value = doc._.blob.polarity\n",
    "#     estimated_rating=(doc._.blob.polarity+1)*2.5\n",
    "#     return estimated_rating,sentiment_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments[['estimated_rating_spacytextblob','estimated_sentiment_spacytextblob']] = comments['comments'].apply(lambda x: pd.Series(analyze_sentiment_spacytextblob(nlp,x)))\n",
    "# comments.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments.to_csv('./csv_output/commentsInfo_flair_textblob_asent_spacytextblob.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('./csv_output/commentsInfo_flair_textblob_asent.csv')\n",
    "\n",
    "\n",
    "df = df[~df['comments'].str.contains('This is an automated posting.')]\n",
    "\n",
    "\n",
    "df.to_csv('./csv_output/commentsInfo_flair_textblob_asent_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different_rows = df[df['estimated_sentiment_textblob'] != df['estimated_sentiment_spacytextblob']]\n",
    "# different_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob=pd.read_csv('./csv_output/commentsInfo_flair_textblob_asent_clean.csv')\n",
    "ob['estimated_rating_textblob']=ob['estimated_rating_textblob']\n",
    "obj=ob[['comments','estimated_rating_flair','estimated_rating_textblob','estimated_rating_asent','pos_value_asent','neg_value_asent','probability','estimated_sentiment_flair','estimated_sentiment_textblob','compound_value_asent','neu_value_asent','estimated_subjectivity_textblob']]\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.to_csv('./csv_output/rating_observations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw=pd.read_csv('./csv_output/rating_observations.csv')\n",
    "\n",
    "# def map_sentiment(sentiment):\n",
    "#     return 1 if sentiment == 'POSITIVE' else -1\n",
    "\n",
    "# raw['sentiment_mapping'] = raw['estimated_sentiment_flair'].apply(map_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition1 = raw['estimated_sentiment_flair'].apply(lambda x: 1 if x == 'POSITIVE' else -1)\n",
    "condition2 = raw['estimated_sentiment_textblob'].apply(lambda x: 1 if x > 0 else -1)\n",
    "condition3 = raw['compound_value_asent'].apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "different_signs_condition = (condition1 != condition2) | (condition2 != condition3)\n",
    "result_df = raw[different_signs_condition]\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./csv_output/observe_diff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"./csv_output/DT_rule.csv\")\n",
    "\n",
    "le_result = LabelEncoder()\n",
    "data['result'] = le_result.fit_transform(data['result'])\n",
    "\n",
    "le_flair = LabelEncoder()\n",
    "data['estimated_sentiment_flair'] = le_flair.fit_transform(data['estimated_sentiment_flair'])\n",
    "\n",
    "# 选择输入变量和目标变量\n",
    "X = data[['pos_value_asent','neg_value_asent','probability','estimated_sentiment_flair','estimated_sentiment_textblob','compound_value_asent','neu_value_asent','estimated_subjectivity_textblob']]\n",
    "y = data['result']\n",
    "\n",
    "# 初始化决策树模型\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "\n",
    "# 进行5折交叉验证\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "print(\"Accuracy scores for each fold: \", scores)\n",
    "print(\"Average accuracy: \", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"./csv_output/DT_rule.csv\")\n",
    "\n",
    "# 将'POSITIVE', 'NEGATIVE', 和'NEUTRAL'转换为数值\n",
    "le_result = LabelEncoder()\n",
    "data['result'] = le_result.fit_transform(data['result'])\n",
    "\n",
    "le_flair = LabelEncoder()\n",
    "data['estimated_sentiment_flair'] = le_flair.fit_transform(data['estimated_sentiment_flair'])\n",
    "\n",
    "# 选择输入变量和目标变量\n",
    "X = data[['pos_value_asent','neg_value_asent','probability','estimated_sentiment_flair','estimated_sentiment_textblob','compound_value_asent','neu_value_asent','estimated_subjectivity_textblob']]\n",
    "y = data['result']\n",
    "\n",
    "# 初始化决策树模型\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 定义要搜索的参数网格\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4,5],\n",
    "    'min_samples_split': [2,3,4, 5,6,7,8,9, 10],\n",
    "    'min_samples_leaf': [1, 2, 3,4]\n",
    "}\n",
    "\n",
    "# 使用GridSearchCV进行搜索\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# 打印最佳参数和相应的准确率\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# 保存最佳模型\n",
    "joblib.dump(grid_search.best_estimator_, './fileOutput/best_decision_tree_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"./csv_output/DT_rule.csv\")\n",
    "\n",
    "# 将'POSITIVE', 'NEGATIVE', 和'NEUTRAL'转换为数值\n",
    "le_result = LabelEncoder()\n",
    "data['result'] = le_result.fit_transform(data['result'])\n",
    "\n",
    "le_flair = LabelEncoder()\n",
    "data['estimated_sentiment_flair'] = le_flair.fit_transform(data['estimated_sentiment_flair'])\n",
    "\n",
    "# 选择输入变量和目标变量\n",
    "X = data[['pos_value_asent','neg_value_asent','probability','estimated_sentiment_flair','estimated_sentiment_textblob','compound_value_asent','neu_value_asent','estimated_subjectivity_textblob']]\n",
    "y = data['result']\n",
    "\n",
    "# 初始化随机森林模型\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 定义要搜索的参数网格\n",
    "# param_grid = {\n",
    "#     'n_estimators': [10, 50, 100, 200],\n",
    "#     'max_depth': [3, 4, 5],\n",
    "#     'min_samples_split': [2, 3, 4, 5],\n",
    "#     'min_samples_leaf': [1, 2, 3, 4]\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5,10,15, 20,30,40,50,100, 200],\n",
    "    'max_depth': [1, 2, 3,None],\n",
    "    'min_samples_split': [2,3,4, 5,6,7,8,9, 10],\n",
    "    'min_samples_leaf': [1, 2,3,4, 5,6,7,8,9, 10],\n",
    "    'bootstrap':[True,False],\n",
    "    'max_features':['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# 使用GridSearchCV进行搜索\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# 打印最佳参数和相应的准确率\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# 保存最佳模型\n",
    "joblib.dump(grid_search.best_estimator_, './fileOutput/best_random_forest_model.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final comments and user dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect_langs\n",
    "\n",
    "raw=pd.read_csv('./dataSource/reviews.csv')\n",
    "raw = raw.drop(columns=['date', 'id'])\n",
    "\n",
    "def is_all_english_text(text):\n",
    "    try:\n",
    "        langs = detect_langs(text)\n",
    "        for lang in langs:\n",
    "            if lang.lang != 'en':\n",
    "                return False\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "raw = raw[raw['comments'].apply(is_all_english_text)]\n",
    "raw = raw[~raw['comments'].str.contains('This is an automated posting.')]\n",
    "\n",
    "raw['userID'] = pd.factorize(raw['reviewer_id'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import re\n",
    "\n",
    "raw = raw.drop(columns=['reviewer_id'])\n",
    "raw_reset = raw.reset_index(drop=True)\n",
    "\n",
    "\n",
    "raw_reset['comments'] = raw_reset['comments'].apply(lambda x: re.sub(r'<br/>', '\\n', x))\n",
    "raw_reset['comments'] = raw_reset['comments'].apply(lambda x: re.sub(r'\\n+', '\\n', x))\n",
    "\n",
    "commentsInfo=raw_reset[['listing_id','userID','comments']]\n",
    "\n",
    "commentsInfo.to_csv('./csv_output/commentsInfo.csv', index=False)\n",
    "\n",
    "commentsInfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userInfo=raw_reset[['userID','reviewer_name']]\n",
    "userInfo = userInfo.rename(columns={'reviewer_name': 'userName'})\n",
    "userInfo = userInfo.drop_duplicates(subset=['userID'])\n",
    "\n",
    "def process_username(username):\n",
    "    pattern = re.compile(r'[^a-zA-Z0-9_]+')\n",
    "    return re.sub(pattern, '_', username)\n",
    "\n",
    "\n",
    "userInfo['userName'] = userInfo['userName'].apply(process_username)\n",
    "\n",
    "used_usernames = set()\n",
    "\n",
    "for index, row in userInfo.iterrows():\n",
    "    username = row['userName']\n",
    "    \n",
    "    if username in used_usernames:\n",
    "        while True:\n",
    "            new_username = f\"{username}_{random.randint(1, 999)}\"\n",
    "            if new_username not in used_usernames and len(new_username) <= 20:\n",
    "                break\n",
    "        userInfo.at[index, 'userName'] = new_username\n",
    "        used_usernames.add(new_username)\n",
    "    else:\n",
    "        used_usernames.add(username)\n",
    "\n",
    "def generate_password(length):\n",
    "    characters = string.ascii_letters + string.digits + string.punctuation\n",
    "    password = ''.join(random.choice(characters) for _ in range(length))\n",
    "    return password\n",
    "\n",
    "\n",
    "userInfo['password'] = userInfo.apply(lambda row: generate_password(random.randint(6, 20)), axis=1)\n",
    "userInfo.to_csv('./csv_output/userInfo.csv', index=False)\n",
    "\n",
    "userInfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_ids = userInfo['userName'].duplicated()\n",
    "\n",
    "\n",
    "duplicate=userInfo[duplicate_ids]\n",
    "duplicate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_ids = userInfo['userID'].duplicated()\n",
    "\n",
    "\n",
    "duplicate=userInfo[duplicate_ids]\n",
    "duplicate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final rating estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from flair.nn import Classifier\n",
    "from flair.data import Sentence\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.special import expit, erf\n",
    "import joblib\n",
    "import spacy\n",
    "import asent\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_mapping(score):\n",
    "    mapped_score = 5 / (1 + math.exp(-score))\n",
    "    return mapped_score\n",
    "\n",
    "def tanh_mapping(score):\n",
    "    mapped_score = 2.5 * math.tanh(score) + 2.5\n",
    "    return mapped_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('./fileOutput/best_random_forest_model.joblib')\n",
    "comments=pd.read_csv('./csv_output/commentsInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('/content/drive/My Drive/gp/best_random_forest_model.joblib')\n",
    "comments=pd.read_csv('/content/drive/My Drive/gp/commentsInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_analysis_init():\n",
    "    classifier = Classifier.load('sentiment')\n",
    "    nlp = spacy.blank('en')\n",
    "    nlp.add_pipe('sentencizer')\n",
    "\n",
    "    # add the rule-based sentiment model\n",
    "    nlp.add_pipe(\"asent_en_v1\")\n",
    "    return classifier,nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_mapping(score, sentiment_value):\n",
    "    a = 2.0  \n",
    "\n",
    "\n",
    "    normalized_score = max(0, min(1, (score - 0.5) / 0.5))\n",
    "\n",
    "\n",
    "    center = 0.99 if sentiment_value == 'POSITIVE' else 0.01\n",
    "\n",
    "\n",
    "    mapped_score = math.exp(-a * abs(normalized_score - center))\n",
    "\n",
    "    mapped_score = mapped_score * 5.0\n",
    "\n",
    "    return mapped_score\n",
    "\n",
    "\n",
    "def analyze_sentiment_flair(classifier,text):\n",
    "    sentence = Sentence(text)\n",
    "    classifier.predict(sentence)\n",
    "\n",
    "    positivity_score = sentence.labels[0].score\n",
    "    sentiment_value = sentence.labels[0].value\n",
    "\n",
    "    estimated_rating = exponential_mapping(positivity_score, sentiment_value)\n",
    "\n",
    "    return estimated_rating, sentiment_value,positivity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_textblob(text):\n",
    "    testimonial = TextBlob(text)\n",
    "    \n",
    "    sentiment_value = testimonial.sentiment.polarity\n",
    "    subjectivity_value = testimonial.sentiment.subjectivity\n",
    "    # estimated_rating=(testimonial.sentiment.polarity+1)*2.5\n",
    "    # return estimated_rating,sentiment_value,subjectivity_value\n",
    "    return sentiment_value,subjectivity_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sentiment_mapping(neg,neu,pos,compound):\n",
    "    neg_weight=5\n",
    "    neu_weight=10\n",
    "    pos_weight=5\n",
    "    # composite_score = - (neg_weight * neg) + (neu_weight * neu) + (pos_weight * pos)\n",
    "    composite_score=(pos_weight * pos + neu_weight * neu - neg_weight * neg) / (pos_weight + neu_weight + neg_weight)\n",
    "    composite_score=erf(composite_score)\n",
    "    mapped_score=5.0*expit((composite_score+(compound+1)*0.5)/2)\n",
    "\n",
    "    return mapped_score\n",
    "\n",
    "\n",
    "def analyze_sentiment_asent(nlp,text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    neg_value = doc._.polarity.negative\n",
    "    neu_value = doc._.polarity.neutral\n",
    "    pos_value = doc._.polarity.positive\n",
    "    compound_value=doc._.polarity.compound\n",
    "    # estimated_rating=sentiment_mapping(neg_value,neu_value,pos_value,compound_value)\n",
    "    # return neg_value,neu_value,pos_value,compound_value,estimated_rating\n",
    "    return neg_value,neu_value,pos_value,compound_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(classifier,nlp,text):\n",
    "    \n",
    "    estimated_rating, sentiment_flair,positivity_flair=analyze_sentiment_flair(classifier,text)\n",
    "    sentiment_textblob,subjectivity_textblob=analyze_sentiment_textblob(text)\n",
    "    neg_asent,neu_asent,pos_asent,compound_asent=analyze_sentiment_asent(nlp,text)\n",
    "   \n",
    "    return estimated_rating,pos_asent,neg_asent,positivity_flair,sentiment_flair,sentiment_textblob,compound_asent,neu_asent,subjectivity_textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def rating_estimation(model,estimated_rating,pos_asent,neg_asent,positivity_flair,sentiment_flair,sentiment_textblob,compound_asent,neu_asent,subjectivity_textblob):\n",
    "#     rating_list=[2,2.5,3]\n",
    "#     sentiment_list=['NEGATIVE','POSITIVE']\n",
    "#     if positivity_flair>=0.9:\n",
    "#         return estimated_rating\n",
    "#     else:\n",
    "#         sentiment_flair = sentiment_list.index(sentiment_flair)\n",
    "#         feature_names=['pos_value_asent','neg_value_asent','probability','estimated_sentiment_flair','estimated_sentiment_textblob','compound_value_asent','neu_value_asent','estimated_subjectivity_textblob']\n",
    "#         model_input=np.array([[pos_asent,neg_asent,positivity_flair,sentiment_flair,sentiment_textblob,compound_asent,neu_asent,subjectivity_textblob]])\n",
    "#         model_input_df = pd.DataFrame(model_input, columns=feature_names)\n",
    "#         estimated_rating=rating_list[model.predict(model_input_df)[0]]\n",
    "#     return estimated_rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_estimation(model, data):\n",
    "    rating_list = [2, 2.5, 3]\n",
    "    sentiment_list = ['NEGATIVE', 'POSITIVE']\n",
    "    \n",
    "    # 将情感从文本转换为数字\n",
    "    data['sentiment_flair'] = data['sentiment_flair'].apply(lambda x: sentiment_list.index(x) if x in sentiment_list else x)\n",
    "    \n",
    "    # 选择所有正向的情感，并直接给出评分\n",
    "    positive_mask = data['positivity_flair'] >= 0.9\n",
    "    ratings = data.loc[positive_mask, 'estimated_rating']\n",
    "    \n",
    "    # 选择所有非正向的情感，使用模型进行预测\n",
    "    not_positive_mask = ~positive_mask\n",
    "    not_positive_data = data.loc[not_positive_mask]\n",
    "    if not not_positive_data.empty:\n",
    "        feature_names = ['pos_value_asent', 'neg_value_asent', 'probability', 'estimated_sentiment_flair', 'estimated_sentiment_textblob', 'compound_value_asent', 'neu_value_asent', 'estimated_subjectivity_textblob']\n",
    "        cols=['pos_asent','neg_asent','positivity_flair','sentiment_flair','sentiment_textblob','compound_asent','neu_asent','subjectivity_textblob']\n",
    "        model_input = not_positive_data[cols]\n",
    "        model_input.columns=feature_names\n",
    "        model_predictions = model.predict(model_input)\n",
    "        model_ratings = pd.Series([rating_list[pred] for pred in model_predictions], index=not_positive_data.index)\n",
    "        ratings = pd.concat([ratings, model_ratings])\n",
    "        \n",
    "    # 将评分按照原始的索引排序\n",
    "    ratings = ratings.sort_index()\n",
    "    \n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier,nlp=comment_analysis_init()\n",
    "\n",
    "temp_df = comments['comments'].apply(lambda x: pd.Series(analyze_sentiment_flair(classifier,x)))\n",
    "temp_df.columns = ['estimated_rating', 'sentiment_flair','positivity_flair']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[['sentiment_textblob','subjectivity_textblob']] = comments['comments'].apply(lambda x: pd.Series(analyze_sentiment_textblob(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[['neg_asent','neu_asent','pos_asent','compound_asent']] = comments['comments'].apply(lambda x: pd.Series(analyze_sentiment_asent(nlp,x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df[['estimated_rating','pos_asent', 'neg_asent', 'positivity_flair', 'sentiment_flair', 'sentiment_textblob', 'compound_asent', 'neu_asent', 'subjectivity_textblob']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments['rating'] = temp_df.apply(lambda row: rating_estimation(model, row['estimated_rating'], row['pos_asent'], row['neg_asent'], row['positivity_flair'], row['sentiment_flair'], row['sentiment_textblob'], row['compound_asent'], row['neu_asent'], row['subjectivity_textblob']), axis=1)\n",
    "comments['rating'] = rating_estimation(model, temp_df)\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_csv('/content/drive/My Drive/gp/ratingInfo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "model = joblib.load('./fileOutput/best_random_forest_model.joblib')\n",
    "temp_df=pd.read_csv('./csv_output/temp_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.columns=['pos_asent', 'neg_asent', 'positivity_flair', 'sentiment_flair', 'sentiment_textblob', 'compound_asent', 'neu_asent', 'subjectivity_textblob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['rating'] = rating_estimation(model, temp_df)\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_csv('./csv_output/ratingInfo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('./dataSource/final_data.csv')\n",
    "df=df.drop('Unnamed: 0', axis=1)\n",
    "df.to_csv('./dataSource/final_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./csv_output/poiInfo.csv')\n",
    "df=df.drop('Unnamed: 0', axis=1)\n",
    "df.to_csv('./csv_output/poiInfo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
